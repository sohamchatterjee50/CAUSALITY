{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06c3216-756f-4a79-bd7f-cde152848b85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Matching and IPW tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b07b7b-a9c2-4795-943e-dacd0d669cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820c9e5-2a42-41ee-b2af-b5c3ddccbe8a",
   "metadata": {},
   "source": [
    "We define a simulator for vaccine hesitancy data, where all variables are binary. X represents vaccine hesitancy, T if an individual gets vaccinated and Y if they recover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dad8e83-191b-4372-94d5-8e610da2655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vaccine_hesitancy_SCM (remove_confounding=False, n_samples=1000):\n",
    "#     # X = vaccine hesitancy:\n",
    "#     # epsilon_x\n",
    "#     epsilon_x = np.random.choice(2, n_samples, p = [0.7, 0.3], replace = True)\n",
    "#     x = epsilon_x\n",
    "    \n",
    "#     # T = get vaccinated:\n",
    "    \n",
    "#     if remove_confounding:\n",
    "#         t = np.random.choice(2, n_samples, p = [0.5, 0.5], replace = True)\n",
    "#     else:\n",
    "#         # epsilon_t_0 = Ber(0.9):\n",
    "#         epsilon_t_0 = np.random.choice(2, n_samples, p = [0.1, 0.9], replace = True)\n",
    "#         # epsilon_t_1 = Ber(0.1):\n",
    "#         epsilon_t_1 = np.random.choice(2, n_samples, p = [0.9, 0.1], replace = True)\n",
    "#         # This is just a way to say that P(T|X=1) = P(epsilon_t_1) and P(T|X=0) = P(epsilon_t_0) \n",
    "#         t = epsilon_t_1*x + epsilon_t_0*(1-x)\n",
    "    \n",
    "#     # Y = recover\n",
    "#     # epsilons for all combinations of values for X and T\n",
    "#     # P(Y=1|X=0, T=0)= Ber(0.6)\n",
    "#     epsilon_y_00 = np.random.choice(2, n_samples, p = [0.4, 0.6], replace = True)\n",
    "#     # P(Y=1|X=0, T=1)= Ber(0.9)\n",
    "#     epsilon_y_01 = np.random.choice(2, n_samples, p = [0.1, 0.9], replace = True)\n",
    "#     # P(Y=1|X=1, T=0)= Ber(0.5)\n",
    "#     epsilon_y_10 = np.random.choice(2, n_samples, p = [0.5, 0.5], replace = True)\n",
    "#     # P(Y=1|X=1, T=1)= Ber(0.75)\n",
    "#     epsilon_y_11 = np.random.choice(2, n_samples, p = [0.25, 0.75], replace = True)\n",
    "    \n",
    "#     # This is just a way to say that P(Y|X=0, T=0) = P(epsilon_y_00), P(Y|X=0, T=1) = P(epsilon_y_01) etc\n",
    "#     y = x*t*epsilon_y_11 + (1-x)*t*epsilon_y_01 + x*(1-t)*epsilon_y_10 + (1-x)*(1-t)*epsilon_y_00\n",
    "#     df = pd.DataFrame({ \"x\": x, \"t\": t, \"y\": y})\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f261b5-b3ff-45fe-a9e5-2cae0b72e69e",
   "metadata": {},
   "source": [
    "We start by simulating some observational data for vaccine hesitancy, in which people who are not hesitant are also engaging in other behaviours that might help them recover. We compute the Average Treatment Effect (ATE) with these data in a naive way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efd4b62-e436-4614-85b7-d99c4610daa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.7899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treat   age  education  black  hispanic  married  nodegree  re75  \\\n",
       "0    1.0  37.0       11.0    1.0       0.0      1.0       1.0   0.0   \n",
       "1    1.0  22.0        9.0    0.0       1.0      0.0       1.0   0.0   \n",
       "2    1.0  30.0       12.0    1.0       0.0      0.0       0.0   0.0   \n",
       "3    1.0  27.0       11.0    1.0       0.0      0.0       1.0   0.0   \n",
       "4    1.0  33.0        8.0    1.0       0.0      0.0       1.0   0.0   \n",
       "\n",
       "         re78  \n",
       "0   9930.0460  \n",
       "1   3595.8940  \n",
       "2  24909.4500  \n",
       "3   7506.1460  \n",
       "4    289.7899  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate some observational data:\n",
    "#df = vaccine_hesitancy_SCM(n_samples=5000)\n",
    "df=pd.read_csv('lalonde_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f665ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE in observational data: 886.3037307037439\n"
     ]
    }
   ],
   "source": [
    "# Vaccinated people:\n",
    "treatment_group = df[df[\"treat\"]==1]\n",
    "# Non-vaccinated people:\n",
    "control_group = df[df[\"treat\"]==0]\n",
    "\n",
    "# if len(treatment_group[treatment_group[\"x\"]==1]) == 0 or len(treatment_group[treatment_group[\"x\"]==0]) == 0:\n",
    "#     if len(control_group[control_group[\"x\"]==1]) == 0 or len(control_group[control_group[\"x\"]==0]) == 0:\n",
    "#         print(\"Positivity is violated, simulate more samples.\")\n",
    "\n",
    "ATE_biased = np.mean(treatment_group[\"re78\"]) - np.mean(control_group[\"re78\"])\n",
    "\n",
    "print(\"ATE in observational data:\", ATE_biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac82402-36e8-4447-bbe6-7a22668d334f",
   "metadata": {},
   "source": [
    "We now simulate some data without any confounding, e.g. what we would get by running a randomized control trial and randomly assigning people to get vaccinated or not. We then compute the Average Treatment Effect (ATE) with these data, which is an unbiased estimate of the real ATE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07fba5ff-b588-4a3f-96fe-32abff18d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rct = vaccine_hesitancy_SCM(n_samples=10000, remove_confounding=True)\n",
    "# # Vaccinated people:\n",
    "# treatment_group_rct = df_rct[df_rct[\"t\"]==1]\n",
    "# # Non-vaccinated people:\n",
    "# control_group_rct = df_rct[df_rct[\"t\"]==0]\n",
    "\n",
    "# ATE_rct = np.mean(treatment_group_rct[\"y\"]) - np.mean(control_group_rct[\"y\"])\n",
    "\n",
    "# print(\"ATE in an uncofounded setting (e.g. randomized controlled trial (RCT)):\", ATE_rct, \"(should be close to 0.3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1b1756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.7899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treat   age  education  black  hispanic  married  nodegree  re75  \\\n",
       "0    1.0  37.0       11.0    1.0       0.0      1.0       1.0   0.0   \n",
       "1    1.0  22.0        9.0    0.0       1.0      0.0       1.0   0.0   \n",
       "2    1.0  30.0       12.0    1.0       0.0      0.0       0.0   0.0   \n",
       "3    1.0  27.0       11.0    1.0       0.0      0.0       1.0   0.0   \n",
       "4    1.0  33.0        8.0    1.0       0.0      0.0       1.0   0.0   \n",
       "\n",
       "         re78  \n",
       "0   9930.0460  \n",
       "1   3595.8940  \n",
       "2  24909.4500  \n",
       "3   7506.1460  \n",
       "4    289.7899  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb8c83-bb99-411e-976d-de5fa92ff8ca",
   "metadata": {},
   "source": [
    "We can see that the estimates for the ATEs are fairly different in the two settings (and we know the ATE in the RCT is supposed to be an approximation of the true ATE, which is close to 0.3), and that the ATE without correction overestimates the effect of the vaccine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90505e-f8f4-4e0d-a414-36e730df4090",
   "metadata": {},
   "source": [
    "## Exact matching:\n",
    "\n",
    "We can now conceptually pair each individual in the treatment group with $X=x$ with an individual in the control group with $X=x$, and remove the ones which don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43cfc792-0ee1-4aee-a05f-68197707a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with nodegree=0 in treatment:  80  and in control:  79\n",
      "Number of people with nodegree=1 in treatment:  217  and in control:  346\n"
     ]
    }
   ],
   "source": [
    "treatment_group_x_0 = treatment_group[treatment_group[\"nodegree\"]==0]\n",
    "treatment_group_x_1 = treatment_group[treatment_group[\"nodegree\"]==1]\n",
    "\n",
    "control_group_x_0 = control_group[control_group[\"nodegree\"]==0]\n",
    "control_group_x_1 = control_group[control_group[\"nodegree\"]==1]\n",
    "\n",
    "print(\"Number of people with nodegree=0 in treatment: \", len(treatment_group_x_0),\" and in control: \", len(control_group_x_0))\n",
    "print(\"Number of people with nodegree=1 in treatment: \", len(treatment_group_x_1),\" and in control: \", len(control_group_x_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cb152-a0df-47f0-a56d-844bb6437175",
   "metadata": {},
   "source": [
    "The numbers of people with nodegree=0 and nodegree=1 is quite unbalanced in the control and treatment.\n",
    "We can also check covariate balancing on the original data P(X|T=0) should the same as P(X|T=1), or in finite data relatively close (we can use standardized mean difference to check how close they are in distribution). Since X is a binary variable, we can just check what happens for X=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81639537-4a56-4c32-9925-c797f8462282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of nodegree=0 on total in treatment:  0.26936026936026936  and in control:  0.18588235294117647\n"
     ]
    }
   ],
   "source": [
    "# approximating P(X=0|T=1)\n",
    "freq_x0_treatment = len(treatment_group_x_0)/len(treatment_group)\n",
    "# approximating P(X=0|T=0)\n",
    "freq_x0_control = len(control_group_x_0)/len(control_group)\n",
    "# In order to be balanced these two should be very close :\n",
    "print(\"Proportion of nodegree=0 on total in treatment: \", freq_x0_treatment, \" and in control: \", freq_x0_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb16df-7f11-498c-8c85-f2ef86a14ee8",
   "metadata": {},
   "source": [
    "We can now perform the matching. Since all units with X=x are conceptually the same, we don't need to actually match the pairs, but we can just keep the same number of people for treatment and control groups for each value of X=x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426c2716-04f7-4fa2-a5be-e3a66884cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing: number of people with nodegree=0 in treatment:  79  and in control:  79\n",
      "After balancing: number of people with nodegree=1 in treatment:  217  and in control:  217\n"
     ]
    }
   ],
   "source": [
    "min_number_x0 = min(len(treatment_group_x_0), len(control_group_x_0))\n",
    "balanced_treatment_x_0 = treatment_group_x_0[0:min_number_x0]\n",
    "balanced_control_x_0 = control_group_x_0[0:min_number_x0]\n",
    "print(\"After balancing: number of people with nodegree=0 in treatment: \", len(balanced_treatment_x_0),\" and in control: \", len(balanced_control_x_0))\n",
    "\n",
    "min_number_x1 = min(len(treatment_group_x_1), len(control_group_x_1))\n",
    "balanced_treatment_x_1 = treatment_group_x_1[0:min_number_x1]\n",
    "balanced_control_x_1 = control_group_x_1[0:min_number_x1]\n",
    "print(\"After balancing: number of people with nodegree=1 in treatment: \", len(balanced_treatment_x_1),\" and in control: \", len(balanced_control_x_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c5031-6b66-4ebb-ae25-b3dc8ec3cb2d",
   "metadata": {},
   "source": [
    "We can now check again the covariate balancing and see that they are balanced and then just use this smaller dataset to estimate the ATE (which turns out to be closer to the true value than the original confounded case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71d08091-e58d-4f73-8ea8-cf5a38e674b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of X=0 on total in treatment:  0.2668918918918919  and in control:  0.2668918918918919\n",
      "ATE after balancing: 701.6755812837837\n"
     ]
    }
   ],
   "source": [
    "balanced_treatment = pd.concat([balanced_treatment_x_0, balanced_treatment_x_1])\n",
    "balanced_control = pd.concat([balanced_control_x_1, balanced_control_x_0])\n",
    "\n",
    "# approximating P(X=0|T=1)\n",
    "freq_x0_treatment_matching = len(balanced_treatment_x_0)/len(balanced_treatment)\n",
    "# approximating P(X=0|T=0)\n",
    "freq_x0_control_matching = len(balanced_control_x_0)/len(balanced_control)\n",
    "print(\"Proportion of X=0 on total in treatment: \", freq_x0_treatment_matching, \" and in control: \", freq_x0_control_matching)\n",
    "\n",
    "ATE_matching = np.mean(balanced_treatment[\"re78\"]) - np.mean(balanced_control[\"re78\"])\n",
    "print(\"ATE after balancing:\", ATE_matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812a878-4688-49bb-bda1-09f1c74aff91",
   "metadata": {},
   "source": [
    "We now used only one variable X for simplicity as the adjustment set. In general this method works also with more than one variable in the adjustment set, and if the variables are not discrete can also use a distance metric to match the units. Unfortunately, this method discared a lot of data, making the estimation less stable.\n",
    "\n",
    "## Propensity scores:\n",
    "We now compute $P(T=1|X)$ for each value of $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16d1dd9c-d2a6-43f1-bb81-477fb8bbcbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5031446540880503 : true value 0.5,  0.38543516873889877 : true value 0.4\n"
     ]
    }
   ],
   "source": [
    "x0_group = pd.concat([treatment_group_x_0,control_group_x_0])\n",
    "x1_group = pd.concat([treatment_group_x_1,control_group_x_1])\n",
    "\n",
    "propensity_score_x0 = len(treatment_group_x_0)/len(x0_group)\n",
    "propensity_score_x1 = len(treatment_group_x_1)/len(x1_group)\n",
    "\n",
    "print(propensity_score_x0, \": true value 0.5, \",  propensity_score_x1, \": true value 0.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8558d56-7067-443f-890b-a9bfb3f6b3f2",
   "metadata": {},
   "source": [
    "We could do matching on the values of propensity scores (this is called propensity score matching), but in this case it doesn't really improve things since the probabilities are quite different for every combination of X. Otherwise it can be seen as a way of clustering values of X that have a similar effect on T.\n",
    "\n",
    "## Inverse probability weighting\n",
    "\n",
    "Instead we just use the formula to compute a weighted average for treatment and control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "433b3e9c-09e3-4c1e-b2fc-308c3a0ad267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE after IPW: 784.0364507960767\n"
     ]
    }
   ],
   "source": [
    "number_of_all_samples = len(df)\n",
    "\n",
    "weighted_sum_treatment_0 = sum(treatment_group_x_0[\"re78\"])/  propensity_score_x0\n",
    "weighted_sum_treatment_1 = sum(treatment_group_x_1[\"re78\"])/ propensity_score_x1\n",
    "\n",
    "mean_treatment = (weighted_sum_treatment_0 + weighted_sum_treatment_1) /number_of_all_samples\n",
    "\n",
    "weighted_sum_control_0 = sum(control_group_x_0[\"re78\"])/(1 - propensity_score_x0)\n",
    "weighted_sum_control_1 = sum(control_group_x_1[\"re78\"])/ (1 - propensity_score_x1)\n",
    "\n",
    "mean_control = (weighted_sum_control_0 + weighted_sum_control_1)/number_of_all_samples\n",
    "\n",
    "ATE_IPW = mean_treatment-mean_control\n",
    "print(\"ATE after IPW:\", ATE_IPW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c8fef-d6d4-4a95-9dd1-461c7b70eee2",
   "metadata": {},
   "source": [
    "## Testing the mean and variance of the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0145dbe3-3d19-4f20-96e0-d8bb51d1d9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784.0364507960767 0.0 1.0 0.0 886.3037307037439 0.0\n"
     ]
    }
   ],
   "source": [
    "def IPW_XTY(df):\n",
    "    # Vaccinated people:\n",
    "    treatment_group = df[df[\"treat\"]==1]\n",
    "    # Non-vaccinated people:\n",
    "    control_group = df[df[\"treat\"]==0]\n",
    "    \n",
    "    number_of_all_samples = len(df)\n",
    "    treatment_group_x_0 = treatment_group[treatment_group[\"nodegree\"]==0]\n",
    "    treatment_group_x_1 = treatment_group[treatment_group[\"nodegree\"]==1]\n",
    "\n",
    "    control_group_x_0 = control_group[control_group[\"nodegree\"]==0]\n",
    "    control_group_x_1 = control_group[control_group[\"nodegree\"]==1]\n",
    "\n",
    "    weighted_sum_treatment_0 = sum(treatment_group_x_0[\"re78\"])/  propensity_score_x0\n",
    "    weighted_sum_treatment_1 = sum(treatment_group_x_1[\"re78\"])/ propensity_score_x1\n",
    "\n",
    "    mean_treatment = weighted_sum_treatment_0 + weighted_sum_treatment_1\n",
    "    mean_treatment = mean_treatment/number_of_all_samples\n",
    "\n",
    "    weighted_sum_control_0 = sum(control_group_x_0[\"re78\"])/(1 - propensity_score_x0)\n",
    "    weighted_sum_control_1 = sum(control_group_x_1[\"re78\"])/ (1 - propensity_score_x1)\n",
    "\n",
    "    mean_control = weighted_sum_control_0 + weighted_sum_control_1 \n",
    "    mean_control = mean_control/number_of_all_samples\n",
    "\n",
    "    return mean_treatment-mean_control\n",
    "\n",
    "def exactMatching_XTY(df):\n",
    "    # Vaccinated people:\n",
    "    treatment_group = df[df[\"treat\"]==1]\n",
    "    # Non-vaccinated people:\n",
    "    control_group = df[df[\"treat\"]==0]\n",
    "    \n",
    "    treatment_group_x_0 = treatment_group[treatment_group[\"re78\"]==0]\n",
    "    treatment_group_x_1 = treatment_group[treatment_group[\"re78\"]==1]\n",
    "\n",
    "    control_group_x_0 = control_group[control_group[\"treat\"]==0]\n",
    "    control_group_x_1 = control_group[control_group[\"treat\"]==1]\n",
    "    \n",
    "    min_number_x0 = min(len(treatment_group_x_0), len(control_group_x_0))\n",
    "    balanced_treatment_x_0 = treatment_group_x_0[0:min_number_x0]\n",
    "    balanced_control_x_0 = control_group_x_0[0:min_number_x0]\n",
    "    \n",
    "    min_number_x1 = min(len(treatment_group_x_1), len(control_group_x_1))\n",
    "    balanced_treatment_x_1 = treatment_group_x_1[0:min_number_x1]\n",
    "    balanced_control_x_1 = control_group_x_1[0:min_number_x1]\n",
    "    \n",
    "    return np.mean(balanced_treatment[\"treat\"]) - np.mean(balanced_control[\"treat\"])\n",
    "\n",
    "ATE_IPW_list = []\n",
    "ATE_matching_list = []\n",
    "ATE_rct_list = []\n",
    "\n",
    "\n",
    "for i in range(0,100):\n",
    "    #df = vaccine_hesitancy_SCM(n_samples=5000)\n",
    "    ATE_IPW_list.append(IPW_XTY(df))\n",
    "    ATE_matching_list.append(exactMatching_XTY(df))\n",
    "    #df_rct = vaccine_hesitancy_SCM(n_samples=5000, remove_confounding=True)\n",
    "    df_rct=df\n",
    "    # Vaccinated people:\n",
    "    treatment_group_rct = df_rct[df_rct[\"treat\"]==1]\n",
    "    # Non-vaccinated people:\n",
    "    control_group_rct = df_rct[df_rct[\"treat\"]==0]\n",
    "    ATE_rct_list.append(np.mean(treatment_group_rct[\"re78\"]) - np.mean(control_group_rct[\"re78\"]))\n",
    "\n",
    "\n",
    "print(np.mean(ATE_IPW_list), np.std(ATE_IPW_list), np.mean(ATE_matching_list), np.std(ATE_matching_list), np.mean(ATE_rct_list), np.std(ATE_rct_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f01dbf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.7899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treat   age  education  black  hispanic  married  nodegree  re75  \\\n",
       "0    1.0  37.0       11.0    1.0       0.0      1.0       1.0   0.0   \n",
       "1    1.0  22.0        9.0    0.0       1.0      0.0       1.0   0.0   \n",
       "2    1.0  30.0       12.0    1.0       0.0      0.0       0.0   0.0   \n",
       "3    1.0  27.0       11.0    1.0       0.0      0.0       1.0   0.0   \n",
       "4    1.0  33.0        8.0    1.0       0.0      0.0       1.0   0.0   \n",
       "\n",
       "         re78  \n",
       "0   9930.0460  \n",
       "1   3595.8940  \n",
       "2  24909.4500  \n",
       "3   7506.1460  \n",
       "4    289.7899  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545226ae-4e20-495e-8b26-0357c7554e5b",
   "metadata": {},
   "source": [
    "## Example with more variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96ce6339-3d7d-4f00-8565-1eb17032fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing: number of people with nodegree=0 and black=0 in treatment:  18  and in control:  18\n",
      "After balancing: number of people with nodegree=0 and black=1 in treatment:  61  and in control:  61\n",
      "After balancing: number of people with nodegree=1 and black=0 in treatment:  41  and in control:  41\n",
      "After balancing: number of people with nodegree=1 and black=1 in treatment:  176  and in control:  176\n"
     ]
    }
   ],
   "source": [
    "# def more_variables_SCM (remove_confounding=False, n_samples=1000):\n",
    "#     epsilon_x1 = np.random.choice(2, n_samples, p = [0.6, 0.4], replace = True)\n",
    "#     x1 = epsilon_x1\n",
    "    \n",
    "#     epsilon_x2 = np.random.choice(2, n_samples, p = [0.7, 0.3], replace = True)\n",
    "#     x2 = epsilon_x2\n",
    "    \n",
    "#     if remove_confounding:\n",
    "#         t = np.random.choice(2, n_samples, p = [0.5, 0.5], replace = True)\n",
    "#     else:\n",
    "#         epsilon_t_00 = np.random.choice(2, n_samples, p = [0.1, 0.9], replace = True)\n",
    "#         epsilon_t_10 = np.random.choice(2, n_samples, p = [0.8, 0.2], replace = True)\n",
    "#         epsilon_t_11 = np.random.choice(2, n_samples, p = [0.95, 0.05], replace = True)\n",
    "#         epsilon_t_01 = np.random.choice(2, n_samples, p = [0.7, 0.3], replace = True)    \n",
    "#         t = epsilon_t_00*(1-x1)*(1-x2) + epsilon_t_01*(1-x1)*x2 + epsilon_t_10*x1*(1-x2) + epsilon_t_11*x1*x2\n",
    "    \n",
    "    \n",
    "#     x = x1 * x2\n",
    "#     epsilon_y_00 = np.random.choice(2, n_samples, p = [0.4, 0.6], replace = True)\n",
    "#     epsilon_y_01 = np.random.choice(2, n_samples, p = [0.1, 0.9], replace = True)\n",
    "#     epsilon_y_10 = np.random.choice(2, n_samples, p = [0.5, 0.5], replace = True)\n",
    "#     epsilon_y_11 = np.random.choice(2, n_samples, p = [0.25, 0.75], replace = True)\n",
    "#     y = x*t*epsilon_y_11 + (1-x)*t*epsilon_y_01 + x*(1-t)*epsilon_y_10 + (1-x)*(1-t)*epsilon_y_00\n",
    "    \n",
    "#     df = pd.DataFrame({ \"x1\": x1, \"x2\": x2, \"t\": t, \"y\": y})\n",
    "#     return df\n",
    "\n",
    "# Simulate some observational data:\n",
    "#df2 = more_variables_SCM(n_samples=5000)\n",
    "df2=df\n",
    "\n",
    "# Vaccinated people:\n",
    "t_group = df2[df2[\"treat\"]==1]\n",
    "# Non-vaccinated people:\n",
    "c_group = df2[df2[\"treat\"]==0]\n",
    "\n",
    "ATE_biased = np.mean(t_group[\"re78\"]) - np.mean(c_group[\"re78\"])\n",
    "#df2_rct = more_variables_SCM(n_samples=10000, remove_confounding=True)\n",
    "# Vaccinated people:\n",
    "#t_rct = df2_rct[df2_rct[\"t\"]==1]\n",
    "# Non-vaccinated people:\n",
    "#c_rct = df2_rct[df2_rct[\"t\"]==0]\n",
    "#print(\"ATE in an uncofounded setting (e.g. randomized controlled trial (RCT)):\", np.mean(t_rct[\"y\"]) - np.mean(c_rct[\"y\"]), \", unadjusted ATE:\", ATE_biased)\n",
    "\n",
    "treatment_group_x_0 = t_group[t_group[\"nodegree\"]==0]\n",
    "treatment_group_x_1 = t_group[t_group[\"nodegree\"]==1]\n",
    "\n",
    "treatment_group_x_00 = treatment_group_x_0[treatment_group_x_0[\"black\"]==0]\n",
    "treatment_group_x_10 = treatment_group_x_1[treatment_group_x_1[\"black\"]==0]\n",
    "treatment_group_x_01 = treatment_group_x_0[treatment_group_x_0[\"black\"]==1]\n",
    "treatment_group_x_11 = treatment_group_x_1[treatment_group_x_1[\"black\"]==1]\n",
    "\n",
    "control_group_x_0 = c_group[c_group[\"nodegree\"]==0]\n",
    "control_group_x_1 = c_group[c_group[\"nodegree\"]==1]\n",
    "\n",
    "control_group_x_00 = control_group_x_0[control_group_x_0[\"black\"]==0]\n",
    "control_group_x_10 = control_group_x_1[control_group_x_1[\"black\"]==0]\n",
    "control_group_x_01 = control_group_x_0[control_group_x_0[\"black\"]==1]\n",
    "control_group_x_11 = control_group_x_1[control_group_x_1[\"black\"]==1]\n",
    "\n",
    "\n",
    "min_number_x_00 = min(len(treatment_group_x_00), len(control_group_x_00))\n",
    "balanced_treatment_x_00 = treatment_group_x_00[0:min_number_x_00]\n",
    "balanced_control_x_00 = control_group_x_00[0:min_number_x_00]\n",
    "print(\"After balancing: number of people with nodegree=0 and black=0 in treatment: \", len(balanced_treatment_x_00),\" and in control: \", len(balanced_control_x_00))\n",
    "\n",
    "min_number_x_01 = min(len(treatment_group_x_01), len(control_group_x_01))\n",
    "balanced_treatment_x_01 = treatment_group_x_01[0:min_number_x_01]\n",
    "balanced_control_x_01 = control_group_x_01[0:min_number_x_01]\n",
    "print(\"After balancing: number of people with nodegree=0 and black=1 in treatment: \", len(balanced_treatment_x_01),\" and in control: \", len(balanced_control_x_01))\n",
    "\n",
    "min_number_x_10 = min(len(treatment_group_x_10), len(control_group_x_10))\n",
    "balanced_treatment_x_10 = treatment_group_x_10[0:min_number_x_10]\n",
    "balanced_control_x_10 = control_group_x_10[0:min_number_x_10]\n",
    "print(\"After balancing: number of people with nodegree=1 and black=0 in treatment: \", len(balanced_treatment_x_10),\" and in control: \", len(balanced_control_x_10))\n",
    "\n",
    "min_number_x_11 = min(len(treatment_group_x_11), len(control_group_x_11))\n",
    "balanced_treatment_x_11 = treatment_group_x_11[0:min_number_x_11]\n",
    "balanced_control_x_11 = control_group_x_11[0:min_number_x_11]\n",
    "print(\"After balancing: number of people with nodegree=1 and black=1 in treatment: \", len(balanced_treatment_x_11),\" and in control: \", len(balanced_control_x_11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15b574f5-b4ae-472a-b899-7d50e9c26e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE after balancing: 624.4923380405407\n"
     ]
    }
   ],
   "source": [
    "balanced_treatment2 = pd.concat([balanced_treatment_x_00, balanced_treatment_x_01, balanced_treatment_x_10, balanced_treatment_x_11])\n",
    "balanced_control2 = pd.concat([balanced_control_x_01, balanced_control_x_00, balanced_control_x_11, balanced_control_x_10])\n",
    "\n",
    "ATE_matching2 = np.mean(balanced_treatment2[\"re78\"]) - np.mean(balanced_control2[\"re78\"])\n",
    "print(\"ATE after balancing:\", ATE_matching2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f998cc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing: number of people with nodegree=0 and black=0 and hispanic=0 in treatment:  13  and in control:  13\n",
      "After balancing: number of people with nodegree=0 and black=0 and hispanic=1 in treatment:  4  and in control:  4\n",
      "After balancing: number of people with nodegree=0 and black=1 hispanic=1 in treatment:  0  and in control:  0\n",
      "After balancing: number of people with nodegree=0 and black=1 hispanic=0 in treatment:  61  and in control:  61\n",
      "After balancing: number of people with nodegree=1 and black=0 hispanic=0 in treatment:  17  and in control:  17\n",
      "After balancing: number of people with nodegree=1 and black=0 hispanic=1 in treatment:  24  and in control:  24\n",
      "After balancing: number of people with nodegree=1 and black=1 hispanic=1 in treatment:  0  and in control:  0\n",
      "After balancing: number of people with nodegree=1 and black=1 hispanic=0 in treatment:  176  and in control:  176\n"
     ]
    }
   ],
   "source": [
    "treatment_group_x_000 = treatment_group_x_00[treatment_group_x_00[\"hispanic\"]==0]\n",
    "treatment_group_x_001 = treatment_group_x_00[treatment_group_x_00[\"hispanic\"]==1]\n",
    "treatment_group_x_100 = treatment_group_x_10[treatment_group_x_10[\"hispanic\"]==0]\n",
    "treatment_group_x_101 = treatment_group_x_10[treatment_group_x_10[\"hispanic\"]==1]\n",
    "treatment_group_x_011 = treatment_group_x_01[treatment_group_x_01[\"hispanic\"]==1]\n",
    "treatment_group_x_010 = treatment_group_x_01[treatment_group_x_01[\"hispanic\"]==0]\n",
    "treatment_group_x_111 = treatment_group_x_11[treatment_group_x_11[\"hispanic\"]==1]\n",
    "treatment_group_x_110 = treatment_group_x_11[treatment_group_x_11[\"hispanic\"]==0]\n",
    "\n",
    "\n",
    "control_group_x_000 = control_group_x_00[control_group_x_00[\"hispanic\"]==0]\n",
    "control_group_x_001 = control_group_x_00[control_group_x_00[\"hispanic\"]==1]\n",
    "control_group_x_100 = control_group_x_10[control_group_x_10[\"hispanic\"]==0]\n",
    "control_group_x_101 = control_group_x_10[control_group_x_10[\"hispanic\"]==1]\n",
    "control_group_x_011 = control_group_x_01[control_group_x_01[\"hispanic\"]==1]\n",
    "control_group_x_010 = control_group_x_01[control_group_x_01[\"hispanic\"]==0]\n",
    "control_group_x_111 = control_group_x_11[control_group_x_11[\"hispanic\"]==1]\n",
    "control_group_x_110 = control_group_x_11[control_group_x_11[\"hispanic\"]==0]\n",
    "\n",
    "min_number_x_000 = min(len(treatment_group_x_000), len(control_group_x_000))\n",
    "balanced_treatment_x_000 = treatment_group_x_000[0:min_number_x_000]\n",
    "balanced_control_x_000 = control_group_x_000[0:min_number_x_000]\n",
    "print(\"After balancing: number of people with nodegree=0 and black=0 and hispanic=0 in treatment: \", len(balanced_treatment_x_000),\" and in control: \", len(balanced_control_x_000))\n",
    "\n",
    "min_number_x_001 = min(len(treatment_group_x_001), len(control_group_x_001))\n",
    "balanced_treatment_x_001 = treatment_group_x_001[0:min_number_x_001]\n",
    "balanced_control_x_001 = control_group_x_001[0:min_number_x_001]\n",
    "print(\"After balancing: number of people with nodegree=0 and black=0 and hispanic=1 in treatment: \", len(balanced_treatment_x_001),\" and in control: \", len(balanced_control_x_001))\n",
    "\n",
    "\n",
    "\n",
    "min_number_x_011 = min(len(treatment_group_x_011), len(control_group_x_011))\n",
    "balanced_treatment_x_011 = treatment_group_x_011[0:min_number_x_011]\n",
    "balanced_control_x_011 = control_group_x_011[0:min_number_x_011]\n",
    "print(\"After balancing: number of people with nodegree=0 and black=1 hispanic=1 in treatment: \", len(balanced_treatment_x_011),\" and in control: \", len(balanced_control_x_011))\n",
    "\n",
    "min_number_x_010 = min(len(treatment_group_x_010), len(control_group_x_010))\n",
    "balanced_treatment_x_010 = treatment_group_x_010[0:min_number_x_010]\n",
    "balanced_control_x_010 = control_group_x_010[0:min_number_x_010]\n",
    "print(\"After balancing: number of people with nodegree=0 and black=1 hispanic=0 in treatment: \", len(balanced_treatment_x_010),\" and in control: \", len(balanced_control_x_010))\n",
    "\n",
    "\n",
    "\n",
    "min_number_x_100 = min(len(treatment_group_x_100), len(control_group_x_100))\n",
    "balanced_treatment_x_100 = treatment_group_x_100[0:min_number_x_100]\n",
    "balanced_control_x_100 = control_group_x_100[0:min_number_x_100]\n",
    "print(\"After balancing: number of people with nodegree=1 and black=0 hispanic=0 in treatment: \", len(balanced_treatment_x_100),\" and in control: \", len(balanced_control_x_100))\n",
    "\n",
    "min_number_x_101 = min(len(treatment_group_x_101), len(control_group_x_101))\n",
    "balanced_treatment_x_101 = treatment_group_x_101[0:min_number_x_101]\n",
    "balanced_control_x_101 = control_group_x_101[0:min_number_x_101]\n",
    "print(\"After balancing: number of people with nodegree=1 and black=0 hispanic=1 in treatment: \", len(balanced_treatment_x_101),\" and in control: \", len(balanced_control_x_101))\n",
    "\n",
    "min_number_x_111 = min(len(treatment_group_x_111), len(control_group_x_111))\n",
    "balanced_treatment_x_111 = treatment_group_x_111[0:min_number_x_111]\n",
    "balanced_control_x_111 = control_group_x_111[0:min_number_x_111]\n",
    "print(\"After balancing: number of people with nodegree=1 and black=1 hispanic=1 in treatment: \", len(balanced_treatment_x_111),\" and in control: \", len(balanced_control_x_111))\n",
    "\n",
    "min_number_x_110 = min(len(treatment_group_x_110), len(control_group_x_110))\n",
    "balanced_treatment_x_110 = treatment_group_x_110[0:min_number_x_110]\n",
    "balanced_control_x_110 = control_group_x_110[0:min_number_x_110]\n",
    "print(\"After balancing: number of people with nodegree=1 and black=1 hispanic=0 in treatment: \", len(balanced_treatment_x_110),\" and in control: \", len(balanced_control_x_110))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60c68ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE after balancing: 685.5759391864403\n"
     ]
    }
   ],
   "source": [
    "balanced_treatment2 = pd.concat([balanced_treatment_x_000, balanced_treatment_x_001, balanced_treatment_x_010, balanced_treatment_x_011,\n",
    "                                 balanced_treatment_x_100,balanced_treatment_x_101,balanced_treatment_x_110,balanced_treatment_x_111])\n",
    "balanced_control2 = pd.concat([balanced_control_x_000, balanced_control_x_001, balanced_control_x_010, balanced_control_x_011,\n",
    "                               balanced_control_x_100, balanced_control_x_101, balanced_control_x_110, balanced_control_x_111,\n",
    "                               ])\n",
    "\n",
    "ATE_matching2 = np.mean(balanced_treatment2[\"re78\"]) - np.mean(balanced_control2[\"re78\"])\n",
    "print(\"ATE after balancing:\", ATE_matching2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d0953-deb6-4b07-ab1b-d17d4c552da8",
   "metadata": {},
   "source": [
    "Exact matching discarded a lot of data, so the estimate is quite unstable. We now look quickly at propensity scores, which are again not very useful in this case, and then we look at inverse probability weighting which does not discard any data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd5950-82ad-43cf-a5a2-0c741926732f",
   "metadata": {},
   "source": [
    "## Propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcc26c-b54d-4cb6-86b4-61256f2e2f76",
   "metadata": {},
   "source": [
    "We now compute $P(T=1|X)$ for each value of $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ced8671-b333-48c0-9499-e38201009e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x000_group = pd.concat([treatment_group_x_000,control_group_x_000])\n",
    "x001_group = pd.concat([treatment_group_x_001,control_group_x_001])\n",
    "x010_group = pd.concat([treatment_group_x_010,control_group_x_010])\n",
    "x011_group = pd.concat([treatment_group_x_011,control_group_x_011])\n",
    "\n",
    "x100_group = pd.concat([treatment_group_x_100,control_group_x_100])\n",
    "x101_group = pd.concat([treatment_group_x_101,control_group_x_101])\n",
    "x110_group = pd.concat([treatment_group_x_110,control_group_x_110])\n",
    "x111_group = pd.concat([treatment_group_x_111,control_group_x_111])\n",
    "\n",
    "\n",
    "propensity_score_x000 = len(treatment_group_x_000)/len(x000_group)\n",
    "propensity_score_x001 = len(treatment_group_x_001)/len(x001_group)\n",
    "propensity_score_x010 = len(treatment_group_x_010)/len(x010_group)\n",
    "#propensity_score_x011 = len(treatment_group_x_011)/len(x011_group)\n",
    "\n",
    "\n",
    "propensity_score_x100 = len(treatment_group_x_100)/len(x100_group)\n",
    "propensity_score_x101 = len(treatment_group_x_101)/len(x101_group)\n",
    "propensity_score_x110 = len(treatment_group_x_110)/len(x110_group)\n",
    "#propensity_score_x111 = len(treatment_group_x_111)/len(x111_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b986a-4a1f-494b-bd6f-71ab32550538",
   "metadata": {},
   "source": [
    "We could do matching on the values of propensity scores (this is called propensity score matching), but in this case it doesn't really improve things since the probabilities are quite different for every combination of X. Otherwise it can be seen as a way of clustering values of X that have a similar effect on T."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79104ca-d38d-4d53-b4a8-ce26be5da08b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inverse probability weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d43da6b5-bc9d-46a5-8bad-581b0eba2d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE after IPW: 783.4030691284797\n"
     ]
    }
   ],
   "source": [
    "number_of_all_samples = len(df2)\n",
    "\n",
    "weighted_sum_treatment_000 = sum(treatment_group_x_000[\"re78\"])/  propensity_score_x000\n",
    "weighted_sum_treatment_001 = sum(treatment_group_x_001[\"re78\"])/  propensity_score_x001\n",
    "weighted_sum_treatment_010 = sum(treatment_group_x_010[\"re78\"])/ propensity_score_x010\n",
    "weighted_sum_treatment_100 = sum(treatment_group_x_100[\"re78\"])/ propensity_score_x100\n",
    "weighted_sum_treatment_101 = sum(treatment_group_x_101[\"re78\"])/ propensity_score_x101\n",
    "weighted_sum_treatment_110 = sum(treatment_group_x_110[\"re78\"])/ propensity_score_x110\n",
    "\n",
    "\n",
    "mean_treatment2 = weighted_sum_treatment_000 + weighted_sum_treatment_001 + weighted_sum_treatment_010 + weighted_sum_treatment_100 + weighted_sum_treatment_101 + weighted_sum_treatment_110\n",
    "mean_treatment2 = mean_treatment2/number_of_all_samples\n",
    "\n",
    "weighted_sum_control_000 = sum(control_group_x_000[\"re78\"])/(1 - propensity_score_x000)\n",
    "weighted_sum_control_010 = sum(control_group_x_010[\"re78\"])/ (1 - propensity_score_x010)\n",
    "weighted_sum_control_001 = sum(control_group_x_001[\"re78\"])/ (1 - propensity_score_x001)\n",
    "weighted_sum_control_100 = sum(control_group_x_100[\"re78\"])/ (1 - propensity_score_x100)\n",
    "weighted_sum_control_101 = sum(control_group_x_101[\"re78\"])/ (1 - propensity_score_x101)\n",
    "weighted_sum_control_110 = sum(control_group_x_110[\"re78\"])/ (1 - propensity_score_x110)\n",
    "\n",
    "mean_control2 = weighted_sum_control_000 + weighted_sum_control_001 + weighted_sum_control_010 + weighted_sum_control_100 + weighted_sum_control_101 + weighted_sum_control_110\n",
    "mean_control2 = mean_control2/number_of_all_samples\n",
    "\n",
    "ATE_IPW2 = mean_treatment2-mean_control2\n",
    "print(\"ATE after IPW:\", ATE_IPW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65348443",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10582e-4921-4859-98d1-a3843a063305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
